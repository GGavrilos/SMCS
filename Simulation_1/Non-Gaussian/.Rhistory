m = dim(parameters)[1] # number of models
L = matrix(NA, nrow = n, ncol = m) # to store the losses
means= c(0, y[1 : (n - 1)]) # true means
for (i in 1:m){
L[, i]= crps_norm(y, mean = means + eps[i], sd = sqrt(1 + delta[i]))
}
c = matrix(NA, ncol = m, nrow = m) # array to store the c parameters on weekdays
high = 1e10
for (i in 1:m){
for (j in (1:m)[-i]){
tmp = integer(0)
if (delta[i] != delta[j]){
tmp = ((eps[i]) * sqrt(1 + delta[j]) - (eps[j]) * sqrt(1 + delta[i]))/(sqrt(1 + delta[j]) - sqrt(1 + delta[i]))
}
c[i,j]= max(abs(
crps_norm(c(high, -high, tmp), mean = eps[i], sd = sqrt(1 + delta[i])) - crps_norm(c(high, -high, tmp), mean = eps[j], sd = sqrt(1 + delta[j]))))
}
}
lambda = 1/(2 * c)
d = array(0, c(m, m, n))
for (i in 1:m){
for (j in (1:m)[-i]){
d[i, j, ]= L[, i]- L[, j]
}
}
E = E_sup = array(0, c(m, m, n))
for (i in 1:m){
for (j in (1:m)[-i]){
E[i, j, ] = cumprod(1 + lambda[i, j] * d[i, j, ])
E_sup[i, j, ] = cummax(E[i, j, ])
}
}
EE = E_adj = matrix(0, ncol = n, nrow = m)
for (i in 1:m){
EE[i,] = colMeans(E[i, -i,])
}
E_adj = apply(EE, 2, adj)
p_adj_inv = array(0, c(m, m, n))
for (t in 1:n){
p_adj_inv[, , t] = vector_to_matrix(adj_geom(matrix_to_vector(E_sup[, , t])))
}
#-------------------------------------------------------------------------------
# load packages and functions
library(MASS)
library(scoringRules)
source("Adjusting.R")
source("functions.R")
#-------------------------------------------------------------------------------
# Set parameters
alpha = 0.1 # confidence level
n = 1000 # sample size
epsilon = delta = seq(-0.6, 0.6, length.out = 7) # bias and dispersion errors
parameters = expand.grid(epsilon = epsilon, delta = delta)
# model number i, corresponds to the i-th row in parameters
eps = parameters$epsilon
delta= parameters$delta
ind_sup_model = which((eps == 0) & (delta == 0)) # indices of the superior model
id <- as.integer(Sys.getenv("SLURM_ARRAY_TASK_ID"))
set.seed(id)
y = rep(NA, n)
y[1] = rnorm(1)
for (i in 2:n){
y[i] = rnorm(1, mean = y[i - 1])
}
m = dim(parameters)[1] # number of models
L = matrix(NA, nrow = n, ncol = m) # to store the losses
means= c(0, y[1 : (n - 1)]) # true means
for (i in 1:m){
L[, i]= crps_norm(y, mean = means + eps[i], sd = sqrt(1 + delta[i]))
}
c = matrix(NA, ncol = m, nrow = m) # array to store the c parameters on weekdays
high = 1e10
for (i in 1:m){
for (j in (1:m)[-i]){
tmp = integer(0)
if (delta[i] != delta[j]){
tmp = ((eps[i]) * sqrt(1 + delta[j]) - (eps[j]) * sqrt(1 + delta[i]))/(sqrt(1 + delta[j]) - sqrt(1 + delta[i]))
}
c[i,j]= max(abs(
crps_norm(c(high, -high, tmp), mean = eps[i], sd = sqrt(1 + delta[i])) - crps_norm(c(high, -high, tmp), mean = eps[j], sd = sqrt(1 + delta[j]))))
}
}
lambda = 1/(2 * c)
d = array(0, c(m, m, n))
for (i in 1:m){
for (j in (1:m)[-i]){
d[i, j, ]= L[, i]- L[, j]
}
}
E = E_sup = array(0, c(m, m, n))
for (i in 1:m){
for (j in (1:m)[-i]){
E[i, j, ] = cumprod(1 + lambda[i, j] * d[i, j, ])
E_sup[i, j, ] = cummax(E[i, j, ])
}
}
EE = E_adj = matrix(0, ncol = n, nrow = m)
for (i in 1:m){
EE[i,] = colMeans(E[i, -i,])
}
E_adj = apply(EE, 2, adj)
#-------------------------------------------------------------------------------
# load packages and functions
# install.packages("EnvStats", "scoringRules")
library(MASS)
library(EnvStats)
library(scoringRules)
source("Adjusting.R")
source("functions.R")
source("function_c.R")
#-------------------------------------------------------------------------------
# Set parameters
alpha = 0.1 # confidence level
n = 1000 # sample size
p = 0.5 # mixing weight
p1 <- matrix(c(p, 1 - p), nrow = 1)
p2 <- matrix(c(p, 1 - p), nrow = 1)
epsilon = delta = seq(-0.6, 0.6, length.out = 7) # bias and dispersion errors
parameters = expand.grid(epsilon = epsilon, delta = delta)
# model number i, corresponds to the i-th row in parameters
eps = parameters$epsilon
delta= parameters$delta
ind_sup_model = which((eps == 0) & (delta == 0)) # indices of the superior model
id <- as.integer(Sys.getenv("SLURM_ARRAY_TASK_ID"))
set.seed(id)
y = rep(NA, n)
y[1] <- 0 # We start with a reference value y = 0. #
for (i in 2:n){
mu_i <- c(atan(y[i - 1]), -atan(y[i - 1]))
sd_i <- c(1 + sqrt(abs(y[i - 1])), 1 + sqrt(abs(y[i - 1])))
y[i] <- rnormMix(1, mean1 = mu_i[1], mean2 = mu_i[2],
sd1 = sqrt(sd_i[1]), sd2  = sqrt(sd_i[2]),
p.mix = p) # Draw a new outcome y. #
}
m = dim(parameters)[1] # number of models
L = matrix(NA, nrow = n, ncol = m) # to store the losses
means = c(0, y[1 : (n - 1)]) # true means
p_matrix <- matrix(rep(c(p, 1 - p), each = n), nrow = n) # parameter needs to have the right dimension
for (i in 1:m){
L[, i] <- crps_mixnorm(y, m = cbind(means + parameters[i, 1], -means + parameters[i, 1]),
s = sqrt(cbind(1 + sqrt(abs(means)) + parameters[i, 2], 1 + sqrt(abs(means)) + parameters[i, 2])),
w = p_matrix) # Compute loss values. #
}
c = matrix(NA, ncol = m, nrow = m) # array to store the c parameters
for (i in 1:m){
for (j in 1:m){
mu1 <- means + parameters[i, 1]
mu2 <- means + parameters[j, 1]
sigma1 <- cbind(1 + sqrt(abs(means)) + parameters[j, 2], 1 + sqrt(abs(means)) + parameters[j, 2])
sigma2 <- cbind(1 + sqrt(abs(means)) + parameters[j, 2], 1 + sqrt(abs(means)) + parameters[j, 2])
c[i,j] <- predictable_bound(mu1, mu2, sqrt(sigma1), sqrt(sigma2), p1, p2)
}
}
lambda = 1/(2 * c)
d = array(0, c(m, m, n))
for (i in 1:m){
for (j in (1:m)[-i]){
d[i, j, ]= L[, i]- L[, j]
}
}
E = E_sup = array(0, c(m, m, n))
for (i in 1:m){
for (j in (1:m)[-i]){
E[i, j, ] = cumprod(1 + lambda[i, j] * d[i, j, ])
E_sup[i, j, ] = cummax(E[i, j, ])
}
}
EE = E_adj = matrix(0, ncol = n, nrow = m)
for (i in 1:m){
EE[i,] = colMeans(E[i, -i,])
}
E_adj = apply(EE, 2, adj)
p_adj_inv = array(0, c(m, m, n))
warnings()
View(EE)
View(E_adj)
View(E[,,10])
View(c)
c = matrix(NA, ncol = m, nrow = m) # array to store the c parameters
for (i in 1:m){
for (j in 1:m){
mu1 <- means + parameters[i, 1]
mu2 <- means + parameters[j, 1]
sigma1 <- cbind(1 + sqrt(abs(means)) + parameters[i, 2], 1 + sqrt(abs(means)) + parameters[i, 2])
sigma2 <- cbind(1 + sqrt(abs(means)) + parameters[j, 2], 1 + sqrt(abs(means)) + parameters[j, 2])
c[i,j] <- predictable_bound(mu1, mu2, sqrt(sigma1), sqrt(sigma2), p1, p2)
}
}
View(c)
lambda = 1/(2 * c)
d = array(0, c(m, m, n))
for (i in 1:m){
for (j in (1:m)[-i]){
d[i, j, ]= L[, i]- L[, j]
}
}
E = E_sup = array(0, c(m, m, n))
for (i in 1:m){
for (j in (1:m)[-i]){
E[i, j, ] = cumprod(1 + lambda[i, j] * d[i, j, ])
E_sup[i, j, ] = cummax(E[i, j, ])
}
}
EE = E_adj = matrix(0, ncol = n, nrow = m)
for (i in 1:m){
EE[i,] = colMeans(E[i, -i,])
}
E_adj = apply(EE, 2, adj)
View(E_adj)
View(E[,,10])
load("~/polybox - Georgios Gavrilopoulos (georgios.gavrilopoulos@stat.math.ethz.ch)@polybox.ethz.ch/PhD/Projects/SMCS/RCode/Simulation_1/size_e_summarized.rda")
size_e_summarized
load("~/polybox - Georgios Gavrilopoulos (georgios.gavrilopoulos@stat.math.ethz.ch)@polybox.ethz.ch/PhD/Projects/SMCS/RCode/Simulation_1/size_p_summarized.rda")
size_p_summarized
load("~/polybox - Georgios Gavrilopoulos (georgios.gavrilopoulos@stat.math.ethz.ch)@polybox.ethz.ch/PhD/Projects/SMCS/RCode/Simulation_1/freq_e_summarized.rda")
load("~/polybox - Georgios Gavrilopoulos (georgios.gavrilopoulos@stat.math.ethz.ch)@polybox.ethz.ch/PhD/Projects/SMCS/RCode/Simulation_1/freq_p_summarized.rda")
freq_p_summarized
min(size_p_summarized)
min(freq_p_summarized)
plot(freq_p_summarized, type = "l")
plot(freq_p_summarized[1:1000], type = "l")
min(freq_e_summarized)
# load packages and functions
# install.packages("EnvStats", "scoringRules")
library(MASS)
library(EnvStats)
library(scoringRules)
source("Adjusting.R")
source("functions.R")
source("function_c.R")
#-------------------------------------------------------------------------------
# Set parameters
alpha = 0.1 # confidence level
n = 1000 # sample size
p = 0.5 # mixing weight
p1 <- matrix(c(p, 1 - p), nrow = 1)
p2 <- matrix(c(p, 1 - p), nrow = 1)
epsilon = delta = seq(-0.6, 0.6, length.out = 7) # bias and dispersion errors
parameters = expand.grid(epsilon = epsilon, delta = delta)
View(parameters)
# model number i, corresponds to the i-th row in parameters
eps = parameters$epsilon
delta= parameters$delta
ind_sup_model = which((eps == 0) & (delta == 0)) # indices of the superior model
y = rep(NA, n)
y[1] <- 0 # We start with a reference value y = 0. #
for (i in 2:n){
mu_i <- c(atan(y[i - 1]), -atan(y[i - 1]))
sd_i <- c(1 + sqrt(abs(y[i - 1])), 1 + sqrt(abs(y[i - 1])))
y[i] <- rnormMix(1, mean1 = mu_i[1], mean2 = mu_i[2],
sd1 = sqrt(sd_i[1]), sd2  = sqrt(sd_i[2]),
p.mix = p) # Draw a new outcome y. #
}
m = dim(parameters)[1] # number of models
L = matrix(NA, nrow = n, ncol = m) # to store the losses
means = c(0, y[1 : (n - 1)]) # true means
p_matrix <- matrix(rep(c(p, 1 - p), each = n), nrow = n) # parameter needs to have the right dimension
for (i in 1:m){
L[, i] <- crps_mixnorm(y, m = cbind(means + parameters[i, 1], -means + parameters[i, 1]),
s = sqrt(cbind(1 + sqrt(abs(means)) + parameters[i, 2], 1 + sqrt(abs(means)) + parameters[i, 2])),
w = p_matrix) # Compute loss values. #
}
c = matrix(NA, ncol = m, nrow = m) # array to store the c parameters
for (i in 1:m){
for (j in 1:m){
mu1 <- means + parameters[i, 1]
mu2 <- means + parameters[j, 1]
sigma1 <- cbind(1 + sqrt(abs(means)) + parameters[i, 2], 1 + sqrt(abs(means)) + parameters[i, 2])
sigma2 <- cbind(1 + sqrt(abs(means)) + parameters[j, 2], 1 + sqrt(abs(means)) + parameters[j, 2])
c[i,j] <- predictable_bound(mu1, mu2, sqrt(sigma1), sqrt(sigma2), p1, p2)
}
}
View(L)
#-------------------------------------------------------------------------------
# load packages and functions
# install.packages("EnvStats", "scoringRules")
library(MASS)
library(EnvStats)
library(scoringRules)
source("Adjusting.R")
source("functions.R")
source("function_c.R")
#-------------------------------------------------------------------------------
# Set parameters
alpha = 0.1 # confidence level
n = 1000 # sample size
p = 0.5 # mixing weight
p1 <- matrix(c(p, 1 - p), nrow = 1)
p2 <- matrix(c(p, 1 - p), nrow = 1)
epsilon = delta = seq(-0.6, 0.6, length.out = 7) # bias and dispersion errors
parameters = expand.grid(epsilon = epsilon, delta = delta)
# model number i, corresponds to the i-th row in parameters
eps = parameters$epsilon
delta= parameters$delta
ind_sup_model = which((eps == 0) & (delta == 0)) # indices of the superior model
y = rep(NA, n)
y[1] <- 0 # We start with a reference value y = 0. #
for (i in 2:n){
mu_i <- c(atan(y[i - 1]), -atan(y[i - 1]))
sd_i <- c(1 + sqrt(abs(y[i - 1])), 1 + sqrt(abs(y[i - 1])))
y[i] <- rnormMix(1, mean1 = mu_i[1], mean2 = mu_i[2],
sd1 = sqrt(sd_i[1]), sd2  = sqrt(sd_i[2]),
p.mix = p) # Draw a new outcome y. #
}
m = dim(parameters)[1] # number of models
L = matrix(NA, nrow = n, ncol = m) # to store the losses
means = c(0, y[1 : (n - 1)]) # true means
p_matrix <- matrix(rep(c(p, 1 - p), each = n), nrow = n) # parameter needs to have the right dimension
for (i in 1:m){
L[, i] <- crps_mixnorm(y, m = cbind(means + parameters[i, 1], -means + parameters[i, 1]),
s = sqrt(cbind(1 + sqrt(abs(means)) + parameters[i, 2], 1 + sqrt(abs(means)) + parameters[i, 2])),
w = p_matrix) # Compute loss values. #
}
c = matrix(NA, ncol = m, nrow = m) # array to store the c parameters
for (i in 1:m){
for (j in 1:m){
mu1 <- cbind(means + parameters[i, 1], -means + parameters[i, 1])
mu2 <- cbind(means + parameters[i, 1], -means + parameters[i, 1])
sigma1 <- cbind(1 + sqrt(abs(means)) + parameters[i, 2], 1 + sqrt(abs(means)) + parameters[i, 2])
sigma2 <- cbind(1 + sqrt(abs(means)) + parameters[j, 2], 1 + sqrt(abs(means)) + parameters[j, 2])
c[i,j] <- predictable_bound(mu1, mu2, sqrt(sigma1), sqrt(sigma2), p1, p2)
}
}
################################################################################
########################## Forecasting Simulation  #############################
################################################################################
#-------------------------------------------------------------------------------
# load packages and functions
# install.packages("EnvStats", "scoringRules")
library(MASS)
library(EnvStats)
library(scoringRules)
source("Adjusting.R")
source("functions.R")
source("function_c.R")
#-------------------------------------------------------------------------------
# Set parameters
alpha = 0.1 # confidence level
n = 1000 # sample size
p = 0.5 # mixing weight
p1 <- matrix(c(p, 1 - p), nrow = 1)
p2 <- matrix(c(p, 1 - p), nrow = 1)
epsilon = delta = seq(-0.6, 0.6, length.out = 7) # bias and dispersion errors
parameters = expand.grid(epsilon = epsilon, delta = delta)
# model number i, corresponds to the i-th row in parameters
eps = parameters$epsilon
delta= parameters$delta
ind_sup_model = which((eps == 0) & (delta == 0)) # indices of the superior model
#-------------------------------------------------------------------------------
# Simulate data
y = rep(NA, n)
y[1] <- 0 # We start with a reference value y = 0. #
for (i in 2:n){
mu_i <- c(atan(y[i - 1]), -atan(y[i - 1]))
sd_i <- c(1 + sqrt(abs(y[i - 1])), 1 + sqrt(abs(y[i - 1])))
y[i] <- rnormMix(1, mean1 = mu_i[1], mean2 = mu_i[2],
sd1 = sqrt(sd_i[1]), sd2  = sqrt(sd_i[2]),
p.mix = p) # Draw a new outcome y. #
}
cbind(means + parameters[10, 1], -means + parameters[10, 1])
m = dim(parameters)[1] # number of models
L = matrix(NA, nrow = n, ncol = m) # to store the losses
means = c(0, y[1 : (n - 1)]) # true means
p_matrix <- matrix(rep(c(p, 1 - p), each = n), nrow = n) # parameter needs to have the right dimension
for (i in 1:m){
L[, i] <- crps_mixnorm(y, m = cbind(means + parameters[i, 1], -means + parameters[i, 1]),
s = sqrt(cbind(1 + sqrt(abs(means)) + parameters[i, 2], 1 + sqrt(abs(means)) + parameters[i, 2])),
w = p_matrix) # Compute loss values. #
}
cbind(means + parameters[10, 1], -means + parameters[10, 1])
variances = 1 + sqrt(abs(c(0, y[1:(n-1)])))
variances
means
################################################################################
########################## Forecasting Simulation  #############################
################################################################################
#-------------------------------------------------------------------------------
# load packages and functions
# install.packages("EnvStats", "scoringRules")
library(MASS)
library(EnvStats)
library(scoringRules)
source("Adjusting.R")
source("functions.R")
source("function_c.R")
#-------------------------------------------------------------------------------
# Set parameters
alpha = 0.1 # confidence level
n = 1000 # sample size
p = 0.5 # mixing weight
p1 <- matrix(c(p, 1 - p), nrow = 1)
p2 <- matrix(c(p, 1 - p), nrow = 1)
epsilon = delta = seq(-0.6, 0.6, length.out = 7) # bias and dispersion errors
parameters = expand.grid(epsilon = epsilon, delta = delta)
# model number i, corresponds to the i-th row in parameters
eps = parameters$epsilon
delta= parameters$delta
ind_sup_model = which((eps == 0) & (delta == 0)) # indices of the superior model
# Simulate data
y = rep(NA, n)
y[1] <- 0 # We start with a reference value y = 0. #
for (i in 2:n){
mu_i <- c(atan(y[i - 1]), -atan(y[i - 1]))
sd_i <- c(1 + sqrt(abs(y[i - 1])), 1 + sqrt(abs(y[i - 1])))
y[i] <- rnormMix(1, mean1 = mu_i[1], mean2 = mu_i[2],
sd1 = sqrt(sd_i[1]), sd2  = sqrt(sd_i[2]),
p.mix = p) # Draw a new outcome y. #
}
#-------------------------------------------------------------------------------
# Prepare objects to store
m = dim(parameters)[1] # number of models
L = matrix(NA, nrow = n, ncol = m) # to store the losses
means = atan(c(0, y[1 : (n - 1)])) # true means
variances = 1 + sqrt(abs(c(0, y[1:(n-1)])))
p_matrix <- matrix(rep(c(p, 1 - p), each = n), nrow = n) # parameter needs to have the right dimension
#-------------------------------------------------------------------------------
# Losses of models
for (i in 1:m){
L[, i] <- crps_mixnorm(y, m = cbind(means + parameters[i, 1], -means + parameters[i, 1]),
s = sqrt(cbind(variances + parameters[i, 2], variances + parameters[i, 2])),
w = p_matrix) # Compute loss values. #
}
#-------------------------------------------------------------------------------
# Calculate c-values
c = matrix(NA, ncol = m, nrow = m) # array to store the c parameters
for (i in 1:m){
for (j in 1:m){
mu1 <- cbind(means + parameters[i, 1], -means + parameters[i, 1])
mu2 <- cbind(means + parameters[j, 1], -means + parameters[j, 1])
sigma1 <- cbind(variances + parameters[i, 2], variances + parameters[i, 2])
sigma2 <- cbind(variances + parameters[j, 2], variances + parameters[j, 2])
c[i,j] <- predictable_bound(mu1, mu2, sqrt(sigma1), sqrt(sigma2), p1, p2)
}
}
lambda = 1/(2 * c)
#-------------------------------------------------------------------------------
# Pairwise loss-differences
d = array(0, c(m, m, n))
for (i in 1:m){
for (j in (1:m)[-i]){
d[i, j, ]= L[, i]- L[, j]
}
}
#-------------------------------------------------------------------------------
# Pairwise e-processes
E = E_sup = array(0, c(m, m, n))
# arrays to store the accumulated losses, the variance processes and the e-processes
for (i in 1:m){
for (j in (1:m)[-i]){
E[i, j, ] = cumprod(1 + lambda[i, j] * d[i, j, ])
E_sup[i, j, ] = cummax(E[i, j, ])
}
}
#-------------------------------------------------------------------------------
# e-based approach by the arithmetic mean
EE = E_adj = matrix(0, ncol = n, nrow = m)
for (i in 1:m){
EE[i,] = colMeans(E[i, -i,])
}
E_adj = apply(EE, 2, adj)
#-------------------------------------------------------------------------------
# p-based approach by the geometric mean
p_adj_inv = array(0, c(m, m, n))
for (t in 1:n){
p_adj_inv[, , t] = vector_to_matrix(adj_geom(matrix_to_vector(E_sup[, , t])))
}
#-------------------------------------------------------------------------------
# Compute model confidence sets
MCS_p = MCS_e = rep(list(integer(0)), n)
names(MCS_e) = names(MCS_p) = paste0("t=", 1:n)
MCS_e[[1]]=MCS_p[[1]]=1:m
size_e = freq_e =size_p= freq_p = rep(NA, n)
size_e[1] = size_p[1] = m
freq_e[1] = freq_p[1] = 1
for (t in 2:n){
MCS_p[[t]]= which(rowSums(p_adj_inv[,,t] < 1/alpha) == m)
MCS_p[[t]] = MCS_p[[t]][is.element(MCS_p[[t]], MCS_p[[t - 1]])]
size_p[t] = length(MCS_p[[t]])
freq_p[t] = is.element(ind_sup_model, MCS_p[[t]])
MCS_e[[t]]= which(E_adj[,t] < 1/alpha)
MCS_e[[t]] = MCS_e[[t]][is.element(MCS_e[[t]],MCS_e[[t-1]])]
size_e[t] = length(MCS_e[[t]])
freq_e[t] = is.element(ind_sup_model, MCS_e[[t]])
print(t)
}
load("~/polybox - Georgios Gavrilopoulos (georgios.gavrilopoulos@stat.math.ethz.ch)@polybox.ethz.ch/PhD/Projects/SMCS/RCode/Simulation_1/Sim1_Sebastian/freq_p_summarized.rda")
freq_p_summarized
plot(freq_p_summarized, type = "l", col = "red", ylab = "Coverage Rate")
load("~/polybox - Georgios Gavrilopoulos (georgios.gavrilopoulos@stat.math.ethz.ch)@polybox.ethz.ch/PhD/Projects/SMCS/RCode/Simulation_1/Sim1_Sebastian/freq_p_summarized.rda")
plot(freq_p_summarized, type = "l", col = "red", ylab = "Coverage Rate")
load("~/polybox - Georgios Gavrilopoulos (georgios.gavrilopoulos@stat.math.ethz.ch)@polybox.ethz.ch/PhD/Projects/SMCS/RCode/Simulation_1/Sim1_Sebastian/freq_p.rda")
View(freq_p)
colMeans(freq_p)
load("~/polybox - Georgios Gavrilopoulos (georgios.gavrilopoulos@stat.math.ethz.ch)@polybox.ethz.ch/PhD/Projects/SMCS/RCode/Simulation_1/size_p.rda")
View(size_p)
colMeans(size_p)
load("~/polybox - Georgios Gavrilopoulos (georgios.gavrilopoulos@stat.math.ethz.ch)@polybox.ethz.ch/PhD/Projects/SMCS/RCode/Simulation_1/freq_e.rda")
View(freq_e)
min(freq_e)
load("~/polybox - Georgios Gavrilopoulos (georgios.gavrilopoulos@stat.math.ethz.ch)@polybox.ethz.ch/PhD/Projects/SMCS/RCode/Simulation_1/size_e.rda")
View(size_e)
plot(colMeans(size_e), type = "l", col = "blue", ylab = "Average SMCS Size")
plot(colMeans(size_p), type = "l", col = "blue", ylab = "Average SMCS Size")
lines(colMeans(size_e), type = "l", col = "red", ylab = "Average SMCS Size")
load("~/polybox - Georgios Gavrilopoulos (georgios.gavrilopoulos@stat.math.ethz.ch)@polybox.ethz.ch/PhD/Projects/SMCS/RCode/Simulation_1/Original MCS, Cluster/coverage.rda")
load("~/polybox - Georgios Gavrilopoulos (georgios.gavrilopoulos@stat.math.ethz.ch)@polybox.ethz.ch/PhD/Projects/SMCS/RCode/Simulation_1/Original MCS, Cluster/mcs_hansen.rda")
lines(colMeans(mcs_hansen), type = "l", col = "darkgreen", ylab = "Average SMCS Size")
plot(colMeans(freq_e), type = "l", col = "blue", ylab = "Average SMCS Size")
lines(colMeans(freq_p), type = "l", col = "red", ylab = "Average SMCS Size")
plot(colMeans(freq_e), type = "l", col = "blue", ylab = "Average SMCS Size", ylim = c(0.2, 1.1))
lines(colMeans(freq_p), type = "l", col = "red", ylab = "Average SMCS Size")
lines(colMeans(coverage), type = "l", col = "darkgreen", ylab = "Average SMCS Size")
